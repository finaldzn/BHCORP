{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_creation.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTpUMFEfz6CM",
        "colab_type": "text"
      },
      "source": [
        "# BEEIA - OBJECT RECOGNITION MODEL\n",
        "This is a \"how to\" to get an object recognition model for tensorflow lite, the base model used is SSD_mobilnet_v3\n",
        "\n",
        "\n",
        "Please make sure before running that your colab notebook is using the available gpu \n",
        "\n",
        "execution -> modify the type of execution -> click on gpu\n",
        "\n",
        "Author :\n",
        "- Victor Mouradian *contact*: <victor.mouradian@gmail.com>\n",
        "- Virgile Procureur *contact*: \n",
        "<procureurv@gmail.com>\n",
        "- Paul Pichlak *contact*:\n",
        "<paulpichlak@gmail.com>\n",
        "- Tobias Ohana  *contact*: <tobias1998@hotmail.fr>\n",
        "- Wassim Serradj *contact*: <wassim078@hotmail.fr>\n",
        "\n",
        "The data used is available on github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_tsrtlH14qz",
        "colab_type": "text"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE7Mx1kvHVq",
        "colab_type": "text"
      },
      "source": [
        "Import your drive so you an have access to your files from colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi5TsGY72uz3",
        "colab_type": "code",
        "outputId": "2be2bea5-6604-4e1e-9382-b2f1a9698e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2pShiyFvMmj",
        "colab_type": "text"
      },
      "source": [
        "Then clone the tensorflow repository so we can have access to all the tools tensorflow requires\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swEYKQQI290O",
        "colab_type": "code",
        "outputId": "4eadffee-0e6e-4498-915d-6ca1eefc27ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 32900 (delta 0), reused 7 (delta 0), pack-reused 32893\u001b[K\n",
            "Receiving objects: 100% (32900/32900), 511.90 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (21102/21102), done.\n",
            "Checking out files: 100% (2437/2437), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbwM6N5Rvopj",
        "colab_type": "text"
      },
      "source": [
        "Check tf version, we need 1.15, our 2.x if the code is compatible (but not everything is !)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehnUeLC4s_71",
        "colab_type": "code",
        "outputId": "cacc77db-18bc-41f7-8e5c-8597853aac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eHjJoapwD5Q",
        "colab_type": "text"
      },
      "source": [
        "We then need to use protoc to set up our files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWt-Zdlf49Hk",
        "colab_type": "code",
        "outputId": "eb068f25-32b0-4b9c-ae5e-5e1742da688c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "%%bash\n",
        "ls\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\n",
            "models\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEuUdLCPwLKI",
        "colab_type": "text"
      },
      "source": [
        "Run setup.py next"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpXItmyE88HI",
        "colab_type": "code",
        "outputId": "c4b4cf0f-c1f6-416b-ac07-28dcc1b6ee85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!python models/research/setup.py build"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y2YiGD39KYL",
        "colab_type": "code",
        "outputId": "4ad83175-e3bc-4c15-99be-a08fbe28558e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python models/research/setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating object_detection.egg-info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "reading manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing object_detection-0.1-py3.6.egg\n",
            "Copying object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding object-detection 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Processing dependencies for object-detection==0.1\n",
            "Searching for Cython==0.29.15\n",
            "Best match: Cython 0.29.15\n",
            "Adding Cython 0.29.15 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.2.0\n",
            "Best match: matplotlib 3.2.0\n",
            "Adding matplotlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.6\n",
            "Best match: pyparsing 2.4.6\n",
            "Adding pyparsing 2.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.0.0\n",
            "Best match: setuptools 46.0.0\n",
            "Adding setuptools 46.0.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for object-detection==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiulN6Hdm4Mu",
        "colab_type": "text"
      },
      "source": [
        "Environment variable so the scripts can function properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK2A6IRCVrp8",
        "colab_type": "code",
        "outputId": "04263dc3-bf9b-417b-965a-f6f9a715d2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC_VmCVhwVFq",
        "colab_type": "text"
      },
      "source": [
        "## Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbVqKld4IqhC",
        "colab_type": "text"
      },
      "source": [
        "Dont forget to import the github repo, Following the Setting up notebook is needed before proceeding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15fDlthGIv0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm_OlnLXwaDX",
        "colab_type": "text"
      },
      "source": [
        "This code is to be use if you want to recreate the dataset into a format tensorflow can read."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfjON-ShmmnC",
        "colab_type": "text"
      },
      "source": [
        "Copy the create_pascal_tfrecord file and put into the dataset_tools folder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsmvA_GDwscP",
        "colab_type": "text"
      },
      "source": [
        "### Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q1pz6wHviqC",
        "colab_type": "code",
        "outputId": "df47e4bd-c141-429c-bfc3-e6f9e438f9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "%%bash\n",
        "cd '/content/drive/My Drive/BeeImages/pascalvoc/BDD-PascalVOC-export'\n",
        "python /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
        " --data_dir='/content/drive/My Drive/BeeImages/pascalvoc/BDD-PascalVOC-export' \\\n",
        " --year=VOC2012 \\\n",
        " --set=train\\\n",
        " --output_path='/content/drive/My Drive/BeeImages/pascal_training_n.record'\\\n",
        " --ignore_difficult_instances=True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:189: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:160: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0224 11:06:58.890429 140296384006016 module_wrapper.py:139] From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:160: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0224 11:06:58.911421 140296384006016 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0224 11:06:58.913224 140296384006016 create_pascal_tf_record.py:165] Reading from PASCAL VOC2012 dataset.\n",
            "I0224 11:06:58.915901 140296384006016 create_pascal_tf_record.py:172] On image 0 of 369\n",
            "/content/models/research/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n",
            "I0224 11:06:59.424422 140296384006016 create_pascal_tf_record.py:172] On image 100 of 369\n",
            "I0224 11:06:59.939716 140296384006016 create_pascal_tf_record.py:172] On image 200 of 369\n",
            "I0224 11:07:00.389292 140296384006016 create_pascal_tf_record.py:172] On image 300 of 369\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N2nPX8xwwlB",
        "colab_type": "text"
      },
      "source": [
        "### Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUQCs_RKeA-P",
        "colab_type": "code",
        "outputId": "ddde4bc2-b7e7-403a-a418-28f255dadb23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "%%bash\n",
        "cd '/content/drive/My Drive/BeeImages/pascalvoc/BDD-PascalVOC-export'\n",
        "python /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py \\\n",
        " --data_dir='/content/drive/My Drive/BeeImages/pascalvoc/BDD-PascalVOC-export' \\\n",
        " --year=VOC2012 \\\n",
        " --set=val\\\n",
        " --output_path='/content/drive/My Drive/BeeImages/pascal_val_n.record'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:187: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:160: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0224 10:53:50.755118 139961384032128 module_wrapper.py:139] From /content/models/research/object_detection/dataset_tools/create_pascal_tf_record.py:160: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0224 10:53:51.468425 139961384032128 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0224 10:53:51.470506 139961384032128 create_pascal_tf_record.py:165] Reading from PASCAL VOC2012 dataset.\n",
            "I0224 10:53:51.804042 139961384032128 create_pascal_tf_record.py:172] On image 0 of 96\n",
            "/content/models/research/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}