{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convert_tflite.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTpUMFEfz6CM",
        "colab_type": "text"
      },
      "source": [
        "# BEEIA - OBJECT RECOGNITION MODEL\n",
        "This is a \"how to\" to get an object recognition model for tensorflow lite, the base model used is SSD_mobilnet_v3\n",
        "\n",
        "\n",
        "Please make sure before running that your colab notebook is using the available gpu \n",
        "\n",
        "execution -> modify the type of execution -> click on gpu\n",
        "\n",
        "Author :\n",
        "- Victor Mouradian *contact*: <victor.mouradian@gmail.com>\n",
        "- Virgile Procureur *contact*: \n",
        "<procureurv@gmail.com>\n",
        "- Paul Pichlak *contact*:\n",
        "<paulpichlak@gmail.com>\n",
        "- Tobias Ohana  *contact*: <tobias1998@hotmail.fr>\n",
        "- Wassim Serradj *contact*: <wassim078@hotmail.fr>\n",
        "\n",
        "The data used is available on github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_tsrtlH14qz",
        "colab_type": "text"
      },
      "source": [
        "## Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OE7Mx1kvHVq",
        "colab_type": "text"
      },
      "source": [
        "Import your drive so you an have access to your files from colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi5TsGY72uz3",
        "colab_type": "code",
        "outputId": "2be2bea5-6604-4e1e-9382-b2f1a9698e43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2pShiyFvMmj",
        "colab_type": "text"
      },
      "source": [
        "Then clone the tensorflow repository so we can have access to all the tools tensorflow requires\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swEYKQQI290O",
        "colab_type": "code",
        "outputId": "4eadffee-0e6e-4498-915d-6ca1eefc27ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 32900 (delta 0), reused 7 (delta 0), pack-reused 32893\u001b[K\n",
            "Receiving objects: 100% (32900/32900), 511.90 MiB | 14.33 MiB/s, done.\n",
            "Resolving deltas: 100% (21102/21102), done.\n",
            "Checking out files: 100% (2437/2437), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbwM6N5Rvopj",
        "colab_type": "text"
      },
      "source": [
        "Check tf version, we need 1.15, our 2.x if the code is compatible (but not everything is !)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehnUeLC4s_71",
        "colab_type": "code",
        "outputId": "cacc77db-18bc-41f7-8e5c-8597853aac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eHjJoapwD5Q",
        "colab_type": "text"
      },
      "source": [
        "We then need to use protoc to set up our files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWt-Zdlf49Hk",
        "colab_type": "code",
        "outputId": "eb068f25-32b0-4b9c-ae5e-5e1742da688c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "%%bash\n",
        "ls\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\n",
            "models\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEuUdLCPwLKI",
        "colab_type": "text"
      },
      "source": [
        "Run setup.py next"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpXItmyE88HI",
        "colab_type": "code",
        "outputId": "c4b4cf0f-c1f6-416b-ac07-28dcc1b6ee85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!python models/research/setup.py build"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y2YiGD39KYL",
        "colab_type": "code",
        "outputId": "4ad83175-e3bc-4c15-99be-a08fbe28558e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python models/research/setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating object_detection.egg-info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "reading manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing object_detection-0.1-py3.6.egg\n",
            "Copying object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding object-detection 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Processing dependencies for object-detection==0.1\n",
            "Searching for Cython==0.29.15\n",
            "Best match: Cython 0.29.15\n",
            "Adding Cython 0.29.15 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.2.0\n",
            "Best match: matplotlib 3.2.0\n",
            "Adding matplotlib 3.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==7.0.0\n",
            "Best match: Pillow 7.0.0\n",
            "Adding Pillow 7.0.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.6\n",
            "Best match: pyparsing 2.4.6\n",
            "Adding pyparsing 2.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==46.0.0\n",
            "Best match: setuptools 46.0.0\n",
            "Adding setuptools 46.0.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for object-detection==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiulN6Hdm4Mu",
        "colab_type": "text"
      },
      "source": [
        "Environment variable so the scripts can function properly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK2A6IRCVrp8",
        "colab_type": "code",
        "outputId": "04263dc3-bf9b-417b-965a-f6f9a715d2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxJMvXnMFwLq",
        "colab_type": "text"
      },
      "source": [
        "## Tf lite conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxVoTyZ7qjx",
        "colab_type": "code",
        "outputId": "799d0043-8c5b-4dcb-d8ee-ce783fc9c477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "cd \"/content/models/research\"\n",
        "python object_detection/export_tflite_ssd_graph.py --pipeline_config_path=\"/content/drive/My Drive/BeeImages/model_26022020/ssd_mobilenet_v3_small_coco_2019_08_14/pipeline.config\" --trained_checkpoint_prefix=\"/content/drive/My Drive/BeeImages/model_26022020/ssd_mobilenet_v3_small_coco_2019_08_14/model.ckpt-12000\" --output_directory=\"/content/models/research/object_detection/tmp2/\" --add_postprocessing_op=true"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0323 11:08:45.747211 140709374355328 deprecation_wrapper.py:119] From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0323 11:08:45.751651 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0323 11:08:45.751952 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0323 11:08:45.754243 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0323 11:08:48.051074 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0323 11:08:48.061965 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.062155 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.135376 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.227269 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.299899 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.382250 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0323 11:08:48.460662 140709374355328 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0323 11:08:48.547358 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-03-23 11:08:48.547851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-03-23 11:08:48.551721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-23 11:08:48.551963: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20b4680 executing computations on platform Host. Devices:\n",
            "2020-03-23 11:08:48.551988: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-03-23 11:08:48.641775: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0323 11:08:48.650743 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0323 11:08:48.653946 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0323 11:08:48.894439 140709374355328 deprecation_wrapper.py:119] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:295: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0323 11:08:48.925979 140709374355328 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/BeeImages/model_26022020/ssd_mobilenet_v3_small_coco_2019_08_14/model.ckpt-12000\n",
            "I0323 11:08:49.467215 140709374355328 saver.py:1280] Restoring parameters from /content/drive/My Drive/BeeImages/model_26022020/ssd_mobilenet_v3_small_coco_2019_08_14/model.ckpt-12000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0323 11:08:49.870265 140709374355328 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0323 11:08:49.870559 140709374355328 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 350 variables.\n",
            "I0323 11:08:50.079151 140709374355328 graph_util_impl.py:311] Froze 350 variables.\n",
            "INFO:tensorflow:Converted 350 variables to const ops.\n",
            "I0323 11:08:50.116726 140709374355328 graph_util_impl.py:364] Converted 350 variables to const ops.\n",
            "2020-03-23 11:08:50.171177: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx6E9mxBznHY",
        "colab_type": "text"
      },
      "source": [
        "Use this to get a QUANTIZED model (not working rn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsBd_EVOrdyP",
        "colab_type": "code",
        "outputId": "6f17e977-7ea0-4507-b6f1-ed14a74f816b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "tflite_convert \\\n",
        "  --saved_model_dir='/content/models/research/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14/export/Servo/1582734406' \\\n",
        "  --output_file='/tmp/detect.tflite'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-26 16:58:37.894109: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-26 16:58:37.934824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:37.935458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 16:58:37.935752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:37.937615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 16:58:37.944578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 16:58:37.945029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 16:58:37.947225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 16:58:37.966096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 16:58:37.978144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 16:58:37.978344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:37.979051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:37.979624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 16:58:38.052079: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-26 16:58:38.052385: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55959c7bad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-26 16:58:38.052411: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-26 16:58:38.169711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.170389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55959c7bb2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-26 16:58:38.170418: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-02-26 16:58:38.170619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.171357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 16:58:38.171417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:38.171430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 16:58:38.171438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 16:58:38.171447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 16:58:38.171458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 16:58:38.171466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 16:58:38.171474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 16:58:38.171536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.172037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.172506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 16:58:38.176267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:38.177405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-26 16:58:38.177456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-26 16:58:38.177477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-26 16:58:38.178563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.179234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:38.179826: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-26 16:58:38.179876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "W0226 16:58:38.180588 140247940351872 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "I0226 16:58:38.946048 140247940351872 saver.py:1284] Restoring parameters from /content/models/research/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14/export/Servo/1582734406/variables/variables\n",
            "I0226 16:58:45.857831 140247940351872 convert_saved_model.py:80] The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: set([u'serving_default', u'tensorflow/serving/predict'])\n",
            "I0226 16:58:45.858470 140247940351872 convert_saved_model.py:99] input tensors info: \n",
            "I0226 16:58:45.858656 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: serialized_example\n",
            "I0226 16:58:45.858767 140247940351872 convert_saved_model.py:43]  tensor name: tf_example:0, shape: (), type: DT_STRING\n",
            "I0226 16:58:45.858860 140247940351872 convert_saved_model.py:101] output tensors info: \n",
            "I0226 16:58:45.859014 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: raw_detection_scores\n",
            "I0226 16:58:45.859102 140247940351872 convert_saved_model.py:43]  tensor name: raw_detection_scores:0, shape: (1, 1917, 3), type: DT_FLOAT\n",
            "I0226 16:58:45.859231 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_multiclass_scores\n",
            "I0226 16:58:45.859545 140247940351872 convert_saved_model.py:43]  tensor name: detection_multiclass_scores:0, shape: (1, 100, 3), type: DT_FLOAT\n",
            "I0226 16:58:45.859695 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_classes\n",
            "I0226 16:58:45.859791 140247940351872 convert_saved_model.py:43]  tensor name: detection_classes:0, shape: (1, 100), type: DT_FLOAT\n",
            "I0226 16:58:45.859908 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: num_detections\n",
            "I0226 16:58:45.859992 140247940351872 convert_saved_model.py:43]  tensor name: num_detections:0, shape: (1), type: DT_FLOAT\n",
            "I0226 16:58:45.860100 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_boxes\n",
            "I0226 16:58:45.860182 140247940351872 convert_saved_model.py:43]  tensor name: detection_boxes:0, shape: (1, 100, 4), type: DT_FLOAT\n",
            "I0226 16:58:45.860277 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: raw_detection_boxes\n",
            "I0226 16:58:45.860354 140247940351872 convert_saved_model.py:43]  tensor name: raw_detection_boxes:0, shape: (1, 1917, 4), type: DT_FLOAT\n",
            "I0226 16:58:45.860471 140247940351872 convert_saved_model.py:41] Tensor's key in saved_model's tensor_map: detection_scores\n",
            "I0226 16:58:45.860551 140247940351872 convert_saved_model.py:43]  tensor name: detection_scores:0, shape: (1, 100), type: DT_FLOAT\n",
            "2020-02-26 16:58:45.861238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:45.861835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 16:58:45.861916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:45.861942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 16:58:45.861960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 16:58:45.861981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 16:58:45.862000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 16:58:45.862020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 16:58:45.862053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 16:58:45.862148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:45.862753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:45.863259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 16:58:45.863303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-26 16:58:45.863319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-26 16:58:45.863329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-26 16:58:45.863453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:45.864066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:45.864635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "I0226 16:58:46.615506 140247940351872 saver.py:1284] Restoring parameters from /content/models/research/object_detection/ssd_mobilenet_v3_small_coco_2019_08_14/export/Servo/1582734406/variables/variables\n",
            "2020-02-26 16:58:47.215133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.215808: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2020-02-26 16:58:47.215926: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-02-26 16:58:47.216617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.217208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 16:58:47.217277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:47.217301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 16:58:47.217322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 16:58:47.217342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 16:58:47.217385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 16:58:47.217426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 16:58:47.217455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 16:58:47.217530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.218112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.218678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 16:58:47.218732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-26 16:58:47.218755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-26 16:58:47.218770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-26 16:58:47.218866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.219513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.220077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-02-26 16:58:47.286495: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2020-02-26 16:58:47.286605: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
            "2020-02-26 16:58:47.286623: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\n",
            "W0226 16:58:47.400661 140247940351872 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/util.py:249: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0226 16:58:47.400947 140247940351872 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "I0226 16:58:47.689826 140247940351872 graph_util_impl.py:334] Froze 350 variables.\n",
            "I0226 16:58:47.746764 140247940351872 graph_util_impl.py:394] Converted 350 variables to const ops.\n",
            "2020-02-26 16:58:47.923958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.924743: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "2020-02-26 16:58:47.924888: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-02-26 16:58:47.925507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.926105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 16:58:47.926187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 16:58:47.926212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 16:58:47.926233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 16:58:47.926254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 16:58:47.926277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 16:58:47.926300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 16:58:47.926324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 16:58:47.926445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.927088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.927657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 16:58:47.927707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-26 16:58:47.927728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-26 16:58:47.927738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-26 16:58:47.928062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.928744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 16:58:47.929331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-02-26 16:58:48.244235: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\n",
            "2020-02-26 16:58:48.244282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1202 nodes (-1438), 1390 edges (-1622), time = 223.616ms.\n",
            "2020-02-26 16:58:48.244291: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1202 nodes (0), 1390 edges (0), time = 33.988ms.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tflite_convert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n",
            "    app.run(main=run_main, argv=sys.argv[:1])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n",
            "    _convert_tf1_model(tflite_flags)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\n",
            "    output_data = converter.convert()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\n",
            "    **converter_kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\n",
            "    enable_mlir_converter=enable_mlir_converter)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\n",
            "    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n",
            "tensorflow.lite.python.convert.ConverterError: See console for info.\n",
            "2020-02-26 16:58:50.539414: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ParseSingleExample\n",
            "2020-02-26 16:58:50.539637: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeRaw\n",
            "2020-02-26 16:58:50.539679: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\n",
            "2020-02-26 16:58:50.539717: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg\n",
            "2020-02-26 16:58:50.539742: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\n",
            "2020-02-26 16:58:50.539756: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\n",
            "2020-02-26 16:58:50.539793: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\n",
            "2020-02-26 16:58:50.539810: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg\n",
            "2020-02-26 16:58:50.539837: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng\n",
            "2020-02-26 16:58:50.539881: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\n",
            "2020-02-26 16:58:50.539901: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeGif\n",
            "2020-02-26 16:58:50.539919: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeBmp\n",
            "2020-02-26 16:58:50.541063: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV4\n",
            "2020-02-26 16:58:50.541120: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV4\n",
            "2020-02-26 16:58:50.558411: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 878 operators, 1583 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.598566: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 845 operators, 1514 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.643740: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 845 operators, 1514 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.683957: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 333 operators, 735 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.696017: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 296 operators, 662 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.705883: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 296 operators, 662 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.714514: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 296 operators, 662 arrays (0 quantized)\n",
            "2020-02-26 16:58:50.734193: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.\n",
            "2020-02-26 16:58:50.735605: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 954258\n",
            "2020-02-26 16:58:50.736487: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n",
            " and pasting the following:\n",
            "\n",
            "TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, GATHER, GREATER, GREATER_EQUAL, HARD_SWISH, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MEAN, MINIMUM, MUL, PACK, RESHAPE, RESIZE_BILINEAR, SELECT, SLICE, SPLIT, SQUEEZE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: DecodeBmp, DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV4, ParseSingleExample, Substr.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\n",
            "    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\n",
            "    enable_mlir_converter)\n",
            "Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\n",
            " and pasting the following:\n",
            "\n",
            "TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, GATHER, GREATER, GREATER_EQUAL, HARD_SWISH, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MEAN, MINIMUM, MUL, PACK, RESHAPE, RESIZE_BILINEAR, SELECT, SLICE, SPLIT, SQUEEZE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK. Here is a list of operators for which you will need custom implementations: DecodeBmp, DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV4, ParseSingleExample, Substr.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9zBMVWGzsl2",
        "colab_type": "text"
      },
      "source": [
        "Use this line to get a tflite model but not quantized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlhbA9NkGkRp",
        "colab_type": "code",
        "outputId": "685b1ad8-7063-45a6-ad70-484317a3f98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%bash\n",
        "tflite_convert  --graph_def_file=/content/models/research/object_detection/tmp2/tflite_graph.pb --output_file=/content/models/research/object_detection/tmp2/detect2.tflite \\ --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  --inference_type=FLOAT --mean_values=128 --std_dev_values=127 --change_concat_input_ranges=false --allow_custom_ops"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-02-26 17:24:10.875830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-26 17:24:10.912314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:10.912922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 17:24:10.913266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 17:24:10.915066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 17:24:10.916958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 17:24:10.917329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 17:24:10.919258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 17:24:10.920449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 17:24:10.924718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 17:24:10.924878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:10.925453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:10.925981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 17:24:10.932673: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-26 17:24:10.932986: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55650c882d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-26 17:24:10.933013: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-26 17:24:11.052443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.053140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55650c8832c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-26 17:24:11.053170: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-02-26 17:24:11.053417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.053927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-26 17:24:11.053987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 17:24:11.054015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-26 17:24:11.054031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-26 17:24:11.054049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-26 17:24:11.054071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-26 17:24:11.054089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-26 17:24:11.054104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-26 17:24:11.054183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.054779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.055279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-26 17:24:11.055410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-26 17:24:11.056500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-26 17:24:11.056549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-26 17:24:11.056565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-26 17:24:11.056701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.057323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-26 17:24:11.057918: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-26 17:24:11.057962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tflite_convert\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\n",
            "    app.run(main=run_main, argv=sys.argv[:1])\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\n",
            "    _convert_tf1_model(tflite_flags)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\n",
            "    output_data = converter.convert()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/lite.py\", line 989, in convert\n",
            "    **converter_kwargs)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 412, in toco_convert_graph_def\n",
            "    enable_mlir_converter=enable_mlir_converter)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\n",
            "    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n",
            "tensorflow.lite.python.convert.ConverterError: See console for info.\n",
            "2020-02-26 17:24:12.796232: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess\n",
            "2020-02-26 17:24:12.814262: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1024 operators, 1515 arrays (0 quantized)\n",
            "2020-02-26 17:24:12.844557: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1024 operators, 1515 arrays (0 quantized)\n",
            "2020-02-26 17:24:12.876756: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 193 operators, 441 arrays (1 quantized)\n",
            "2020-02-26 17:24:12.880792: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 165 operators, 385 arrays (1 quantized)\n",
            "2020-02-26 17:24:12.883798: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 165 operators, 385 arrays (1 quantized)\n",
            "2020-02-26 17:24:12.885603: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 165 operators, 385 arrays (1 quantized)\n",
            "2020-02-26 17:24:12.887812: F tensorflow/lite/toco/tooling_util.cc:1728] Array FeatureExtractor/MobilenetV3/Conv/BatchNorm/FusedBatchNormV3, which is an input to the Add operator producing the output array FeatureExtractor/MobilenetV3/Conv/hard_swish/Relu6, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\n",
            "Aborted (core dumped)\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEZaEEHEzyG5",
        "colab_type": "text"
      },
      "source": [
        "Everything is done, you should now have a tflite model ready to use on your android app"
      ]
    }
  ]
}